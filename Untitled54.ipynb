{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d311448c-36ab-498a-8da4-2c9fd047c212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[OK] Artifacts written to: C:\\Users\\NXTWAVE\\Downloads\\Aspect Based Review Miner\n",
      "  C:\\Users\\NXTWAVE\\Downloads\\Aspect Based Review Miner\\model_aspect_sentiment.pkl\n",
      "  C:\\Users\\NXTWAVE\\Downloads\\Aspect Based Review Miner\\processed_absa.h5\n",
      "  C:\\Users\\NXTWAVE\\Downloads\\Aspect Based Review Miner\\build_metadata.yaml\n",
      "  C:\\Users\\NXTWAVE\\Downloads\\Aspect Based Review Miner\\insights.json\n",
      "  C:\\Users\\NXTWAVE\\Downloads\\Aspect Based Review Miner\\eval_predictions_valid.csv\n",
      "  C:\\Users\\NXTWAVE\\Downloads\\Aspect Based Review Miner\\metrics_report.csv\n",
      "  C:\\Users\\NXTWAVE\\Downloads\\Aspect Based Review Miner\\confusion_matrix.csv\n"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "import json, yaml, joblib, re, string, warnings\n",
    "from pathlib import Path\n",
    "from typing import List, Optional, Tuple, Dict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# -------------------- CONFIG (edit if needed) --------------------\n",
    "IN_FILES = [\n",
    "    r\"C:\\Users\\NXTWAVE\\Downloads\\Aspect Based Review Miner\\archive\\Laptop_Train_v2.csv\",\n",
    "    r\"C:\\Users\\NXTWAVE\\Downloads\\Aspect Based Review Miner\\archive\\Laptops_Test_Data_PhaseA.csv\",\n",
    "    r\"C:\\Users\\NXTWAVE\\Downloads\\Aspect Based Review Miner\\archive\\Laptops_Test_Data_PhaseB.csv\",\n",
    "    r\"C:\\Users\\NXTWAVE\\Downloads\\Aspect Based Review Miner\\archive\\Restaurants_Test_Data_PhaseA.csv\",\n",
    "    r\"C:\\Users\\NXTWAVE\\Downloads\\Aspect Based Review Miner\\archive\\Restaurants_Train_v2.csv\",\n",
    "    r\"C:\\Users\\NXTWAVE\\Downloads\\Aspect Based Review Miner\\archive\\restaurants-trial.csv\",\n",
    "]\n",
    "OUT_DIR = Path(r\"C:\\Users\\NXTWAVE\\Downloads\\Aspect Based Review Miner\")\n",
    "\n",
    "# Candidate column names across ABSA datasets\n",
    "TEXT_CANDS      = [\"text\",\"Text\",\"sentence\",\"Sentence\",\"Review\",\"review\",\"ReviewText\",\"reviewText\"]\n",
    "CATEGORY_CANDS  = [\"category\",\"Category\",\"AspectCategory\",\"aspect\",\"Aspect\",\"target\",\"Target\",\"Term\",\"Aspect Term\",\"Aspect_Term\"]\n",
    "POLARITY_CANDS  = [\"polarity\",\"Polarity\",\"sentiment\",\"Sentiment\",\"label\",\"Label\",\"Opinion\"]\n",
    "ID_CANDS        = [\"id\",\"ID\",\"SentenceID\",\"sentence_id\",\"ReviewID\",\"review_id\"]\n",
    "\n",
    "# -------------------- Utils --------------------\n",
    "URL_RE = re.compile(r\"https?://\\S+|www\\.\\S+\", re.IGNORECASE)\n",
    "PUNCT_TABLE = str.maketrans('', '', string.punctuation)\n",
    "\n",
    "\n",
    "def ensure_out():\n",
    "    OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "def pick_first(df: pd.DataFrame, cands: List[str]) -> Optional[str]:\n",
    "    for c in cands:\n",
    "        if c in df.columns:\n",
    "            return c\n",
    "    return None\n",
    "\n",
    "\n",
    "def standardize_category(v: str) -> str:\n",
    "    if not isinstance(v, str):\n",
    "        return \"UNCAT\"\n",
    "    t = v.strip()\n",
    "    t = t.replace(' ', '_')\n",
    "    t = t.upper()\n",
    "    return t or \"UNCAT\"\n",
    "\n",
    "\n",
    "def clean_text(s: str) -> str:\n",
    "    if not isinstance(s, str):\n",
    "        return \"\"\n",
    "    t = BeautifulSoup(s, \"html5lib\").get_text(\" \")\n",
    "    t = URL_RE.sub(\" \", t)\n",
    "    t = t.lower().translate(PUNCT_TABLE)\n",
    "    t = re.sub(r\"[^a-z0-9\\s]\", \" \", t)\n",
    "    t = re.sub(r\"\\s+\", \" \", t).strip()\n",
    "    return t\n",
    "\n",
    "\n",
    "def normalize_absa(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    cols_orig = list(df.columns)\n",
    "    df = df.copy()\n",
    "    df.columns = [c.strip() for c in df.columns]\n",
    "    tcol  = pick_first(df, TEXT_CANDS)\n",
    "    ccol  = pick_first(df, CATEGORY_CANDS)\n",
    "    pcol  = pick_first(df, POLARITY_CANDS)\n",
    "    idcol = pick_first(df, ID_CANDS)\n",
    "    if not tcol:\n",
    "        raise ValueError(f\"No text column found in {cols_orig}\")\n",
    "    keep = {tcol:\"text\"}\n",
    "    if ccol: keep[ccol] = \"category\"\n",
    "    if pcol: keep[pcol] = \"polarity\"\n",
    "    if idcol: keep[idcol] = \"id\"\n",
    "    out = df[list(keep.keys())].rename(columns=keep)\n",
    "    # Standardize\n",
    "    out['text'] = out['text'].astype(str)\n",
    "    if 'category' in out.columns:\n",
    "        out['category'] = out['category'].astype(str).map(standardize_category)\n",
    "    if 'polarity' in out.columns:\n",
    "        out['polarity'] = out['polarity'].astype(str).str.lower().str.strip()\n",
    "        out['polarity'] = out['polarity'].replace({\n",
    "            'conflict':'neutral', 'mixed':'neutral', 'none':'neutral', 'unknown':'neutral'\n",
    "        })\n",
    "        out['polarity'] = out['polarity'].replace({'pos':'positive','neg':'negative'})\n",
    "        out['polarity'] = out['polarity'].replace({'neu':'neutral','neutrality':'neutral'})\n",
    "        # Keep only three classes for modeling\n",
    "        out = out[out['polarity'].isin(['positive','negative','neutral']) | out['polarity'].isna()]\n",
    "    return out\n",
    "\n",
    "\n",
    "def load_all(paths: List[str]) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    labeled = []\n",
    "    unlabeled = []\n",
    "    seen_fps = set()\n",
    "    for p in paths:\n",
    "        fp = Path(p)\n",
    "        if not fp.exists():\n",
    "            continue\n",
    "        # skip duplicates by name and size\n",
    "        sig = (fp.name, fp.stat().st_size)\n",
    "        if sig in seen_fps:\n",
    "            continue\n",
    "        seen_fps.add(sig)\n",
    "        try:\n",
    "            df = pd.read_csv(fp)\n",
    "        except Exception:\n",
    "            try:\n",
    "                df = pd.read_csv(fp, encoding='latin-1')\n",
    "            except Exception:\n",
    "                continue\n",
    "        try:\n",
    "            dfN = normalize_absa(df)\n",
    "        except Exception:\n",
    "            continue\n",
    "        has_lab = ('polarity' in dfN.columns) and dfN['polarity'].notna().any()\n",
    "        if has_lab:\n",
    "            labeled.append(dfN)\n",
    "        else:\n",
    "            unlabeled.append(dfN)\n",
    "    lab = pd.concat(labeled, ignore_index=True, sort=False) if labeled else pd.DataFrame(columns=['text','category','polarity'])\n",
    "    unlab = pd.concat(unlabeled, ignore_index=True, sort=False) if unlabeled else pd.DataFrame(columns=['text','category'])\n",
    "    return lab, unlab\n",
    "\n",
    "\n",
    "# -------------------- Modeling --------------------\n",
    "\n",
    "def build_pipeline(max_features=100000, ngram=(1,2), C=4.0) -> Pipeline:\n",
    "    return Pipeline([\n",
    "        (\"tfidf\", TfidfVectorizer(max_features=max_features, ngram_range=ngram)),\n",
    "        (\"clf\", LogisticRegression(C=C, max_iter=300, class_weight='balanced', n_jobs=-1))\n",
    "    ])\n",
    "\n",
    "\n",
    "def prepare_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    df['text_clean'] = df['text'].map(clean_text)\n",
    "    if 'category' in df.columns:\n",
    "        df['feat'] = '[' + df['category'].fillna('UNCAT') + '] ' + df['text_clean']\n",
    "    else:\n",
    "        df['feat'] = df['text_clean']\n",
    "    return df\n",
    "\n",
    "\n",
    "def train_model(df_labeled: pd.DataFrame, seed=42) -> Tuple[Pipeline, Dict, pd.DataFrame]:\n",
    "    df = df_labeled.dropna(subset=['text']).copy()\n",
    "    df = prepare_features(df)\n",
    "    # Drop rows without polarity\n",
    "    df = df.dropna(subset=['polarity'])\n",
    "    # Small neutral class? keep 3-class anyway; LR with class_weight balances\n",
    "    Xtr, Xva, ytr, yva = train_test_split(df['feat'], df['polarity'], test_size=0.2, random_state=seed, stratify=df['polarity'])\n",
    "    pipe = build_pipeline()\n",
    "    pipe.fit(Xtr, ytr)\n",
    "    yhat = pipe.predict(Xva)\n",
    "    try:\n",
    "        yproba = pipe.predict_proba(Xva)\n",
    "    except Exception:\n",
    "        yproba = None\n",
    "    rep = classification_report(yva, yhat, output_dict=True)\n",
    "    cm = confusion_matrix(yva, yhat, labels=sorted(df['polarity'].unique()))\n",
    "    eval_df = pd.DataFrame({\n",
    "        'text': Xva,\n",
    "        'label_true': yva.reset_index(drop=True),\n",
    "        'label_pred': pd.Series(yhat)\n",
    "    })\n",
    "    return pipe, {\"report\":rep, \"cm\":cm, \"labels\":sorted(df['polarity'].unique())}, eval_df\n",
    "\n",
    "\n",
    "# -------------------- Insights --------------------\n",
    "\n",
    "def compute_insights(df_all: pd.DataFrame) -> Dict:\n",
    "    info: Dict[str, object] = {}\n",
    "    if 'polarity' in df_all.columns and df_all['polarity'].notna().any():\n",
    "        dist = df_all['polarity'].value_counts().to_dict()\n",
    "        info['sentiment_distribution'] = dist\n",
    "    if 'category' in df_all.columns and 'polarity' in df_all.columns:\n",
    "        grouped = df_all.dropna(subset=['category']).groupby(['category','polarity']).size().unstack(fill_value=0)\n",
    "        # Top negative share categories\n",
    "        if 'negative' in grouped.columns:\n",
    "            total = grouped.sum(axis=1)\n",
    "            neg_share = (grouped['negative'] / total.replace(0, np.nan)).fillna(0).sort_values(ascending=False)\n",
    "            info['top_negative_categories'] = neg_share.head(20).round(4).to_dict()\n",
    "        info['by_category'] = grouped.head(50).to_dict()  # trim size\n",
    "    return info\n",
    "\n",
    "\n",
    "# -------------------- Save artifacts --------------------\n",
    "\n",
    "def save_everything(outdir: Path, pipe: Pipeline, metrics: Dict, eval_df: pd.DataFrame, df_labeled: pd.DataFrame, df_unlabeled: pd.DataFrame, loaded_files: List[str]):\n",
    "    outdir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # PKL model\n",
    "    joblib.dump(pipe, outdir/\"model_aspect_sentiment.pkl\")\n",
    "\n",
    "    # HDF5 with labeled (+ optional unlabeled)\n",
    "    try:\n",
    "        store_df = df_labeled.copy()\n",
    "        # Add model predictions on labeled (for reference)\n",
    "        feats = prepare_features(store_df)['feat']\n",
    "        store_df['pred'] = pipe.predict(feats)\n",
    "        store_df.to_hdf(outdir/\"processed_absa.h5\", key='labeled', mode='w')\n",
    "        if not df_unlabeled.empty:\n",
    "            u = prepare_features(df_unlabeled.copy())\n",
    "            # You can also uncomment to score unlabeled:\n",
    "            # df_unlabeled['pred'] = pipe.predict(u['feat'])\n",
    "            df_unlabeled.to_hdf(outdir/\"processed_absa.h5\", key='unlabeled')\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # Metrics CSVs\n",
    "    pd.DataFrame(metrics['report']).to_csv(outdir/\"metrics_report.csv\")\n",
    "    cm_df = pd.DataFrame(metrics['cm'], index=metrics['labels'], columns=metrics['labels'])\n",
    "    cm_df.to_csv(outdir/\"confusion_matrix.csv\")\n",
    "    eval_df.to_csv(outdir/\"eval_predictions_valid.csv\", index=False)\n",
    "\n",
    "    # Insights JSON\n",
    "    insights = compute_insights(df_labeled)\n",
    "    with open(outdir/\"insights.json\", 'w', encoding='utf-8') as f:\n",
    "        json.dump(insights, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    # YAML metadata\n",
    "    meta = {\n",
    "        'inputs': loaded_files,\n",
    "        'schema_labeled': list(df_labeled.columns),\n",
    "        'schema_unlabeled': list(df_unlabeled.columns),\n",
    "        'counts': {\n",
    "            'labeled_rows': int(len(df_labeled)),\n",
    "            'unlabeled_rows': int(len(df_unlabeled)),\n",
    "            'labels': df_labeled['polarity'].value_counts().to_dict() if 'polarity' in df_labeled.columns else {}\n",
    "        },\n",
    "        'model': 'TFIDF + LogisticRegression (class_weight=balanced)',\n",
    "    }\n",
    "    with open(outdir/\"build_metadata.yaml\", 'w', encoding='utf-8') as f:\n",
    "        yaml.safe_dump(meta, f, sort_keys=False)\n",
    "\n",
    "\n",
    "# -------------------- Main --------------------\n",
    "\n",
    "def main():\n",
    "    ensure_out()\n",
    "    labeled, unlabeled = load_all(IN_FILES)\n",
    "    loaded = [p for p in IN_FILES if Path(p).exists()]\n",
    "\n",
    "    if labeled.empty:\n",
    "        raise SystemExit(\"No labeled rows with polarity found. Check your train CSVs.\")\n",
    "\n",
    "    # Train model\n",
    "    pipe, metrics, eval_df = train_model(labeled)\n",
    "\n",
    "    # Save everything\n",
    "    save_everything(OUT_DIR, pipe, metrics, eval_df, labeled, unlabeled, loaded)\n",
    "\n",
    "    print(\"\\n[OK] Artifacts written to:\", OUT_DIR)\n",
    "    for fn in [\n",
    "        \"model_aspect_sentiment.pkl\",\"processed_absa.h5\",\"build_metadata.yaml\",\"insights.json\",\n",
    "        \"eval_predictions_valid.csv\",\"metrics_report.csv\",\"confusion_matrix.csv\"\n",
    "    ]:\n",
    "        print(\" \", OUT_DIR/fn)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f2c5cc-bdd5-410d-8974-bb9bca3c0e56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
